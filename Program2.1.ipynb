{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2024.5.22)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\guest_1\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\guest_1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python numpy scipy scikit-image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.ndimage import label, find_objects, median_filter, shift, distance_transform_edt\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from skimage import morphology, measure\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2gray\n",
    "from tkinter import filedialog, Tk, simpledialog, messagebox\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Video and Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Video selected: C:/BRIN/BRIN/Dataset/Sample 1/Sample 1/7_RGB.avi\n",
      "Depth Video selected: C:/BRIN/BRIN/Dataset/Sample 1/Sample 1/7_CALDP.avi\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "\n",
    "def browse_video():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes(\"-topmost\", True)\n",
    "    filename = filedialog.askopenfilename()\n",
    "    root.destroy()\n",
    "    return filename\n",
    "\n",
    "# Choose Frame\n",
    "def browse_frame(cap, total_frames):\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes(\"-topmost\", True)\n",
    "    frame_number = simpledialog.askinteger(\"Choose Frame\", f\"Enter frame number (1 to {total_frames}):\")\n",
    "    root.destroy()\n",
    "    if frame_number is not None and 1 <= frame_number <= total_frames:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            return None\n",
    "        return frame\n",
    "    else:\n",
    "        messagebox.showwarning(\"Invalid Frame\", \"Please enter a valid frame number.\")\n",
    "        return None\n",
    "    \n",
    "# Input RGB Video\n",
    "RGB_video_path = browse_video()\n",
    "if RGB_video_path:\n",
    "    cap_rgb = cv2.VideoCapture(RGB_video_path)\n",
    "    if not cap_rgb.isOpened():\n",
    "        print(\"Error: Unable to open RGB video.\")\n",
    "    else:\n",
    "        total_frames_rgb = int(cap_rgb.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(\"RGB Video selected:\", RGB_video_path)\n",
    "        rgb_frame = browse_frame(cap_rgb, total_frames_rgb)  # Choose frame from video RGB\n",
    "        if rgb_frame is not None:\n",
    "            cv2.imshow('Original RGB Frame', rgb_frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "# Input Depth Video\n",
    "Depth_video_path = browse_video()\n",
    "if Depth_video_path:\n",
    "    cap_depth = cv2.VideoCapture(Depth_video_path)\n",
    "    if not cap_depth.isOpened():\n",
    "        print(\"Error: Unable to open Depth video.\")\n",
    "    else:\n",
    "        total_frames_depth = int(cap_depth.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(\"Depth Video selected:\", Depth_video_path)\n",
    "        depth_frame = browse_frame(cap_depth, total_frames_depth)  # Choose frame from video Depth\n",
    "        if depth_frame is not None:\n",
    "            cv2.imshow('Original Depth Frame', depth_frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-segmentation of Human Region Using Depth Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth Processing\n",
    "def depth_processing(depth_frame):\n",
    "    if depth_frame is None:\n",
    "        print(\"Error: Depth frame is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Thresholding operations\n",
    "    lower_threshold = 45\n",
    "    upper_threshold = 85\n",
    "    processed_depth = np.zeros_like(depth_frame)\n",
    "    processed_depth[(depth_frame > lower_threshold) & (depth_frame < upper_threshold)] = 255\n",
    "    return processed_depth\n",
    "\n",
    "processed_depth = depth_processing(depth_frame)\n",
    "\n",
    "if processed_depth is not None:\n",
    "    cv2.imshow('Depth Processing', processed_depth)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error in depth processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB processing\n",
    "def depth_processing(depth_frame):\n",
    "    if depth_frame is None:\n",
    "        print(\"Error: Depth frame is None.\")\n",
    "        return None\n",
    "\n",
    "    depth_values = depth_frame.ravel()\n",
    "    depth_values = depth_values[depth_values != 0]\n",
    "    lower_threshold = np.percentile(depth_values, 5)\n",
    "    upper_threshold = np.percentile(depth_values, 68)\n",
    "\n",
    "    depth_enh = np.zeros_like(depth_frame, dtype=np.uint8)\n",
    "    depth_enh[(depth_frame > lower_threshold) & (depth_frame < upper_threshold)] = 255\n",
    "\n",
    "    # Morphological operations to refine the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    depth_enh = cv2.erode(depth_enh, kernel, iterations=2)\n",
    "    depth_enh = cv2.dilate(depth_enh, kernel, iterations=2)\n",
    "\n",
    "    return depth_enh\n",
    "\n",
    "def rgb_processing(rgb_frame, depth_enh):\n",
    "    if rgb_frame is None or depth_enh is None:\n",
    "        print(\"Error: RGB frame or depth enhancement is None.\")\n",
    "        return None\n",
    "\n",
    "    human_region_mask = depth_enh.astype(bool)\n",
    "    human_region = rgb_frame.copy()\n",
    "    human_region[~human_region_mask] = 0\n",
    "\n",
    "    return human_region\n",
    "\n",
    "processed_depth = depth_processing(depth_frame)\n",
    "human_region = rgb_processing(rgb_frame, processed_depth)\n",
    "\n",
    "if human_region is not None:\n",
    "    cv2.imshow('Human Region', human_region)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error in processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing the Pre-segmented region by Restoring The Hair Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "# Function for hair region restoration using GrabCut\n",
    "def restore_hair_region(rgb_frame, human_region):\n",
    "    faces = detect_faces(human_region)\n",
    "    if len(faces) > 0:\n",
    "        x, y, w, h = faces[0]\n",
    "\n",
    "        x1 = max(0, x - int(0.2 * w))\n",
    "        y1 = max(0, y - int(0.2 * h))\n",
    "        x2 = min(rgb_frame.shape[1], x + int(1.2 * w))\n",
    "        y2 = min(rgb_frame.shape[0], y + int(1.2 * h))\n",
    "\n",
    "        mask = np.zeros((rgb_frame.shape[0], rgb_frame.shape[1]), dtype=np.uint8)\n",
    "        rect = (x1, y1, x2 - x1, y2 - y1)\n",
    "        bgdModel = np.zeros((1, 65), np.float64)\n",
    "        fgdModel = np.zeros((1, 65), np.float64)\n",
    "        cv2.grabCut(rgb_frame, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "        hair_mask = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
    "\n",
    "        enhanced_region = np.zeros_like(rgb_frame)\n",
    "        enhanced_region[human_region > 0] = rgb_frame[human_region > 0]\n",
    "        enhanced_region[hair_mask > 0] = rgb_frame[hair_mask > 0]\n",
    "\n",
    "        return enhanced_region\n",
    "    else:\n",
    "        return human_region\n",
    "\n",
    "processed_depth = depth_processing(depth_frame)\n",
    "human_region = rgb_processing(rgb_frame, processed_depth)\n",
    "enhanced_region = restore_hair_region(rgb_frame, human_region)\n",
    "\n",
    "# Display result\n",
    "if enhanced_region is not None:\n",
    "    cv2.imshow('Enhanced Human Region', enhanced_region)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error in processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grow-cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GrowCut segmentation...\n",
      "GrowCut Segmentation Time: 16.667538166046143 seconds\n"
     ]
    }
   ],
   "source": [
    "def detect_faces(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "def get_hair_region(x, y, w, h, image_shape):\n",
    "    # Define the hair area above the face\n",
    "    x1 = x\n",
    "    y1 = max(0, y - int(0.5 * h))\n",
    "    x2 = x + w\n",
    "    y2 = y\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def downsample_image(image, scale):\n",
    "    width = int(image.shape[1] * scale)\n",
    "    height = int(image.shape[0] * scale)\n",
    "    return cv2.resize(image, (width, height))\n",
    "\n",
    "def growcut(image, labels, max_iterations=100):\n",
    "    height, width = labels.shape\n",
    "    strength = np.zeros((height, width), dtype=np.float32)\n",
    "    strength[labels != 0] = 1.0\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        old_labels = labels.copy()\n",
    "        for y in range(1, height-1):\n",
    "            for x in range(1, width-1):\n",
    "                if labels[y, x] == 0:\n",
    "                    continue\n",
    "                neighborhood = [(y-1, x), (y+1, x), (y, x-1), (y, x+1), (y-1, x-1), (y-1, x+1), (y+1, x-1), (y+1, x+1)]\n",
    "                for ny, nx in neighborhood:\n",
    "                    if ny < 0 or ny >= height or nx < 0 or nx >= width:\n",
    "                        continue\n",
    "                    if labels[ny, nx] == 0:\n",
    "                        continue\n",
    "                    dist = np.linalg.norm(image[y, x] - image[ny, nx])\n",
    "                    strength_factor = 1 - dist / 255.0\n",
    "                    if strength_factor * strength[ny, nx] > strength[y, x]:\n",
    "                        strength[y, x] = strength_factor * strength[ny, nx]\n",
    "                        labels[y, x] = labels[ny, nx]\n",
    "        if np.array_equal(labels, old_labels):\n",
    "            break\n",
    "\n",
    "    return labels\n",
    "\n",
    "def growcut_segmentation(enhanced_region, processed_depth):\n",
    "    gray_depth = cv2.cvtColor(processed_depth, cv2.COLOR_BGR2GRAY)\n",
    "    _, depth_mask = cv2.threshold(gray_depth, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    faces = detect_faces(enhanced_region)  \n",
    "    \n",
    "    hair_mask = np.zeros_like(gray_depth, dtype=np.uint8)\n",
    "    for x, y, w, h in faces:\n",
    "        x1, y1, x2, y2 = get_hair_region(x, y, w, h, enhanced_region.shape)\n",
    "        cv2.rectangle(hair_mask, (x1, y1), (x2, y2), 255, -1)\n",
    "\n",
    "    fg_mask_init = cv2.bitwise_or(depth_mask, hair_mask)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask_init, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
    "\n",
    "    height, width = gray_depth.shape\n",
    "    labels = np.zeros((height, width), dtype=np.int32)\n",
    "    labels[fg_mask == 255] = 1\n",
    "    labels[depth_mask == 0] = -1\n",
    "\n",
    "    small_region = downsample_image(enhanced_region, 0.5)\n",
    "    small_depth = downsample_image(processed_depth, 0.5)\n",
    "    small_labels = cv2.resize(labels, (labels.shape[1] // 2, labels.shape[0] // 2), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    print(\"Performing GrowCut segmentation...\")\n",
    "    labels_out = growcut(small_region, small_labels)\n",
    "    labels_out = cv2.medianBlur(labels_out.astype(np.float32), 3)\n",
    "    labels_out = cv2.resize(labels_out, (labels.shape[1], labels.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    grow_cut_rgb = np.repeat(labels_out[:, :, np.newaxis], 3, axis=2).astype(np.uint8) * enhanced_region\n",
    "    \n",
    "    # Obtain mask for hair\n",
    "    hair_mask = labels_out.copy()\n",
    "    hair_mask[hair_mask != 1] = 0  # Set all values other than 1 to 0\n",
    "\n",
    "    # Obtain mask for the body (excluding hair)\n",
    "    body_mask = labels_out.copy()\n",
    "    body_mask[body_mask == 1] = 0  # Set all values of 1 to 0\n",
    "    body_mask[body_mask == -1] = 1  # Set all values of -1 to 1\n",
    "\n",
    "    # Combine GrowCut segmentation result with original color for hair\n",
    "    grow_cut_rgb = np.zeros_like(enhanced_region)\n",
    "    grow_cut_rgb[body_mask.astype(bool)] = enhanced_region[body_mask.astype(bool)]\n",
    "    grow_cut_rgb[hair_mask.astype(bool)] = enhanced_region[hair_mask.astype(bool)]\n",
    "\n",
    "    return labels_out, grow_cut_rgb\n",
    "\n",
    "start_time = time.time()\n",
    "labels_out, grow_cut_rgb = growcut_segmentation(enhanced_region, processed_depth)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"GrowCut Segmentation Time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Tampilkan hasil segmentasi\n",
    "cv2.imshow(\"The result of GrowCut segmentation\", grow_cut_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimap Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GrowCut segmentation...\n",
      "Trimap Generation Time: 10.726121425628662 seconds\n"
     ]
    }
   ],
   "source": [
    "def generate_trimap(labels, kernel_size=5, erosion_iterations=1, dilation_iterations=2):\n",
    "    \"\"\"\n",
    "    Generate a trimap from the segmentation labels.\n",
    "    \"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    \n",
    "    # Define the foreground and background\n",
    "    foreground = (labels == 1).astype(np.uint8)\n",
    "    background = (labels == -1).astype(np.uint8)\n",
    "\n",
    "    # Erode the foreground to get the definite foreground\n",
    "    eroded_foreground = cv2.erode(foreground, kernel, iterations=erosion_iterations)\n",
    "\n",
    "    # Dilate the foreground to get the uncertain region\n",
    "    dilated_foreground = cv2.dilate(foreground, kernel, iterations=dilation_iterations)\n",
    "\n",
    "    # Initialize the trimap with background (0)\n",
    "    trimap = np.zeros_like(labels, dtype=np.uint8)\n",
    "    \n",
    "    # Assign definite foreground (255)\n",
    "    trimap[eroded_foreground == 1] = 255\n",
    "    \n",
    "    # Assign uncertain region (128)\n",
    "    trimap[(dilated_foreground == 1) & (eroded_foreground == 0)] = 128\n",
    "    \n",
    "    return trimap\n",
    "\n",
    "start_time = time.time()\n",
    "labels_out, grow_cut_rgb = growcut_segmentation(enhanced_region, processed_depth)\n",
    "trimap = generate_trimap(labels_out)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Trimap Generation Time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Display segmentation result and trimap\n",
    "cv2.imshow(\"Trimap\", trimap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_trimap(alpha, erosion_size=3, dilation_size=3):\n",
    "    kernel_erosion = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erosion_size, erosion_size))\n",
    "    kernel_dilation = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_size, dilation_size))\n",
    "\n",
    "    foreground = (alpha > 0.8).astype(np.uint8)\n",
    "    background = (alpha < 0.2).astype(np.uint8)\n",
    "\n",
    "    eroded_foreground = cv2.erode(foreground, kernel_erosion)\n",
    "    dilated_background = cv2.dilate(background, kernel_dilation)\n",
    "\n",
    "    new_trimap = np.full(alpha.shape, 128, dtype=np.uint8)\n",
    "    new_trimap[eroded_foreground == 1] = 255\n",
    "    new_trimap[dilated_background == 1] = 0\n",
    "\n",
    "    return new_trimap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed Form Matting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest_1\\AppData\\Local\\Temp\\ipykernel_5380\\1377410286.py:27: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  cov = np.cov(window.reshape(-1, 3).T)\n",
      "c:\\Users\\Guest_1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\Guest_1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Processing Time: 4.899698734283447 seconds\n"
     ]
    }
   ],
   "source": [
    "def closed_form_matting(image, trimap, epsilon=1e-7, win_size=1):\n",
    "    # Convert image to float and normalize\n",
    "    image = image.astype(np.float64) / 255.0\n",
    "    \n",
    "    # Get trimap regions\n",
    "    is_fg = (trimap == 255)\n",
    "    is_bg = (trimap == 0)\n",
    "    is_unknown = (trimap == 128)\n",
    "\n",
    "    # Compute Matting Laplacian\n",
    "    h, w = trimap.shape\n",
    "    win_radius = win_size // 2\n",
    "    win_area = (win_size * 2 + 1) ** 2\n",
    "    \n",
    "    indices = np.arange(h * w).reshape(h, w)\n",
    "    L_data, L_rows, L_cols = [], [], []\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if is_unknown[y, x]:\n",
    "                window = image[max(0, y-win_radius):min(h, y+win_radius+1),\n",
    "                               max(0, x-win_radius):min(w, x+win_radius+1)]\n",
    "                win_indices = indices[max(0, y-win_radius):min(h, y+win_radius+1),\n",
    "                                      max(0, x-win_radius):min(w, x+win_radius+1)]\n",
    "                \n",
    "                mean = np.mean(window, axis=(0, 1))\n",
    "                cov = np.cov(window.reshape(-1, 3).T)\n",
    "                \n",
    "                inv_cov = np.linalg.inv(cov + (epsilon / win_area) * np.eye(3))\n",
    "                \n",
    "                for wy in range(window.shape[0]):\n",
    "                    for wx in range(window.shape[1]):\n",
    "                        w_idx = win_indices[wy, wx]\n",
    "                        if w_idx != indices[y, x]:\n",
    "                            diff = window[wy, wx] - mean\n",
    "                            L_data.append(1 + diff.dot(inv_cov).dot(diff))\n",
    "                            L_rows.append(indices[y, x])\n",
    "                            L_cols.append(w_idx)\n",
    "    \n",
    "    L = csr_matrix((L_data, (L_rows, L_cols)), shape=(h*w, h*w))\n",
    "    L = L + L.T - diags(L.sum(axis=1).A.ravel())\n",
    "    \n",
    "    # Solve for alpha\n",
    "    b = np.zeros(h * w)\n",
    "    b[is_fg.ravel()] = 1\n",
    "    b[is_bg.ravel()] = 0\n",
    "\n",
    "    x = spsolve(L + diags([1e-5] * (h*w)), b)\n",
    "    alpha = np.clip(x.reshape(h, w), 0, 1)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initial trimap generation\n",
    "initial_trimap = generate_trimap(labels_out)\n",
    "\n",
    "# Closed Form Matting\n",
    "alpha_matte = closed_form_matting(grow_cut_rgb, initial_trimap)\n",
    "\n",
    "# Generate new trimap based on refined alpha matte\n",
    "new_trimap = generate_new_trimap(alpha_matte)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total Processing Time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Original Image\", grow_cut_rgb)\n",
    "cv2.imshow(\"Initial Trimap\", initial_trimap)\n",
    "cv2.imshow(\"Alpha Matte\", alpha_matte)\n",
    "cv2.imshow(\"New Trimap\", new_trimap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save results for further analysis\n",
    "# cv2.imwrite(\"initial_trimap.png\", initial_trimap)\n",
    "# cv2.imwrite(\"alpha_matte.png\", (alpha_matte * 255).astype(np.uint8))\n",
    "# cv2.imwrite(\"new_trimap.png\", new_trimap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Based Matting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned-Based Matting Time: 22.084094047546387 seconds\n"
     ]
    }
   ],
   "source": [
    "def learned_based_matting(image, trimap, alpha_initial, window_size=7, c=1.0):\n",
    "    h, w = trimap.shape\n",
    "    n = h * w\n",
    "    \n",
    "    # Create neighborhood matrix\n",
    "    def get_neighbors(i, j):\n",
    "        neighbors = []\n",
    "        for di in range(-window_size//2, window_size//2 + 1):\n",
    "            for dj in range(-window_size//2, window_size//2 + 1):\n",
    "                if 0 <= i + di < h and 0 <= j + dj < w:\n",
    "                    neighbors.append((i + di) * w + (j + dj))\n",
    "        return neighbors\n",
    "\n",
    "    # Construct F matrix\n",
    "    F_data, F_row, F_col = [], [], []\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if trimap[i, j] == 128:  # Unknown region\n",
    "                neighbors = get_neighbors(i, j)\n",
    "                weights = np.ones(len(neighbors)) / len(neighbors)  # Simple average weights\n",
    "                for k, neighbor in enumerate(neighbors):\n",
    "                    F_data.append(weights[k])\n",
    "                    F_row.append(i * w + j)\n",
    "                    F_col.append(neighbor)\n",
    "\n",
    "    F = csr_matrix((F_data, (F_row, F_col)), shape=(n, n))\n",
    "\n",
    "    # Construct identity matrix for known pixels\n",
    "    I_known = diags([1 if trimap.flatten()[i] != 128 else 0 for i in range(n)])\n",
    "\n",
    "    # Solve the quadratic cost equation\n",
    "    A = diags([1] * n) - F.T\n",
    "    b = c * I_known * alpha_initial.flatten()\n",
    "\n",
    "    alpha_refined = spsolve(A.T @ A + c * I_known, A.T @ b)\n",
    "    alpha_refined = np.clip(alpha_refined.reshape(h, w), 0, 1)\n",
    "\n",
    "    return alpha_refined\n",
    "\n",
    "# Usage\n",
    "start_time = time.time()\n",
    "\n",
    "learned_alpha = learned_based_matting(grow_cut_rgb, initial_trimap, alpha_matte)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Learned-Based Matting Time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Original Image\", grow_cut_rgb)\n",
    "cv2.imshow(\"Initial Alpha Matte\", alpha_matte)\n",
    "cv2.imshow(\"Learned-Based Alpha Matte\", learned_alpha)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save results\n",
    "# cv2.imwrite(\"learned_alpha_matte.png\", (learned_alpha * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Matting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_resolution(image, scale_factor=2):\n",
    "    return cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "rgb_frame = increase_resolution(rgb_frame)\n",
    "depth_frame = increase_resolution(depth_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(image):\n",
    "    # Load the pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    # Create a mask\n",
    "    face_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    # Draw rectangles around the faces on the mask\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(face_mask, (x, y), (x+w, y+h), 255, -1)\n",
    "    \n",
    "    return face_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown pixels in original trimap: 6586\n",
      "Unknown pixels in refined trimap: 42738\n",
      "Reduction in unknown pixels: -36152\n"
     ]
    }
   ],
   "source": [
    "def refine_trimap_and_segment(alpha_matte, original_trimap, face_mask, threshold_low=0.1, threshold_high=0.9, face_threshold_low=0.05, face_threshold_high=0.8):\n",
    "    refined_trimap = np.zeros_like(original_trimap)\n",
    "    \n",
    "    # Apply different thresholds for face area\n",
    "    refined_trimap[face_mask & (alpha_matte <= face_threshold_low)] = 0\n",
    "    refined_trimap[face_mask & (alpha_matte >= face_threshold_high)] = 255\n",
    "    refined_trimap[face_mask & (alpha_matte > face_threshold_low) & (alpha_matte < face_threshold_high)] = 128\n",
    "    \n",
    "    # Apply normal thresholds for the rest of the body\n",
    "    body_mask = ~face_mask.astype(bool)\n",
    "    refined_trimap[body_mask & (alpha_matte <= threshold_low)] = 0\n",
    "    refined_trimap[body_mask & (alpha_matte >= threshold_high)] = 255\n",
    "    refined_trimap[body_mask & (alpha_matte > threshold_low) & (alpha_matte < threshold_high)] = 128\n",
    "\n",
    "    # Create final segmentation map\n",
    "    segmentation_map = np.zeros_like(alpha_matte)\n",
    "    segmentation_map[alpha_matte >= 0.5] = 1\n",
    "    \n",
    "    return refined_trimap, segmentation_map\n",
    "\n",
    "def expand_head_region(segmentation_map, face_mask, expansion_factor=1.2):\n",
    "    # Calculate bounding box of face region\n",
    "    y, x = np.where(face_mask)\n",
    "    if len(y) == 0 or len(x) == 0:  # No face detected\n",
    "        return segmentation_map\n",
    "    \n",
    "    top, bottom, left, right = y.min(), y.max(), x.min(), x.max()\n",
    "    \n",
    "    # Expand bounding box\n",
    "    height = bottom - top\n",
    "    width = right - left\n",
    "    center_y, center_x = (top + bottom) // 2, (left + right) // 2\n",
    "    new_height = int(height * expansion_factor)\n",
    "    new_width = int(width * expansion_factor)\n",
    "    \n",
    "    new_top = max(0, center_y - new_height // 2)\n",
    "    new_bottom = min(segmentation_map.shape[0], center_y + new_height // 2)\n",
    "    new_left = max(0, center_x - new_width // 2)\n",
    "    new_right = min(segmentation_map.shape[1], center_x + new_width // 2)\n",
    "    \n",
    "    # Expand segmentation in the new bounding box\n",
    "    segmentation_map[new_top:new_bottom, new_left:new_right] = 1\n",
    "    \n",
    "    # # Tambahkan operasi dilasi\n",
    "    # kernel = np.ones((5,5), np.uint8)\n",
    "    # segmentation_map = cv2.dilate(segmentation_map.astype(np.uint8), kernel, iterations=2)\n",
    "   \n",
    "   \n",
    "    return segmentation_map\n",
    "\n",
    "def apply_segmentation(image, segmentation_map):\n",
    "    segmented_image = image.copy()\n",
    "    segmented_image[segmentation_map == 0] = [0, 0, 0]  # Set background to black\n",
    "    return segmented_image\n",
    "\n",
    "# Create face mask\n",
    "face_mask = detect_face(grow_cut_rgb)\n",
    "\n",
    "# Refine trimap and create segmentation\n",
    "refined_trimap, final_segmentation = refine_trimap_and_segment(learned_alpha, initial_trimap, face_mask)\n",
    "\n",
    "# Expand head region\n",
    "final_segmentation = expand_head_region(final_segmentation, face_mask)\n",
    "\n",
    "# Apply the final segmentation to the original image\n",
    "final_segmented_image = apply_segmentation(grow_cut_rgb, final_segmentation)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Refined Trimap\", refined_trimap)\n",
    "cv2.imshow(\"Final Segmentation Map\", final_segmentation.astype(np.float32))\n",
    "cv2.imshow(\"Final Segmented Image\", final_segmented_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print some statistics\n",
    "unknown_pixels_original = np.sum(initial_trimap == 128)\n",
    "unknown_pixels_refined = np.sum(refined_trimap == 128)\n",
    "print(f\"Unknown pixels in original trimap: {unknown_pixels_original}\")\n",
    "print(f\"Unknown pixels in refined trimap: {unknown_pixels_refined}\")\n",
    "print(f\"Reduction in unknown pixels: {unknown_pixels_original - unknown_pixels_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_segmentation(segmentation_map, original_image, body_mask):\n",
    "    segmentation_map = body_mask.astype(np.float32)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilated_map = cv2.dilate(segmentation_map, kernel, iterations=2)\n",
    "    _, sharp_map = cv2.threshold(dilated_map, 0.4, 1, cv2.THRESH_BINARY)\n",
    "    cleaned_map = cv2.morphologyEx(sharp_map, cv2.MORPH_CLOSE, kernel)\n",
    "    feather_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    feathered_map = cv2.normalize(cv2.filter2D(cleaned_map, -1, feather_kernel), None, 0, 1, cv2.NORM_MINMAX)\n",
    "    sharpened = cv2.addWeighted(original_image, 1.5, cv2.GaussianBlur(original_image, (0, 0), 10), -0.45, 0)\n",
    "    foreground = cv2.multiply(sharpened.astype(np.float32)/255, np.repeat(feathered_map[:,:,np.newaxis], 3, axis=2))\n",
    "    hsv = cv2.cvtColor(foreground.astype(np.uint8), cv2.COLOR_BGR2HSV)\n",
    "    blue_mask = cv2.inRange(hsv, np.array([100,50,50]), np.array([140,255,255]))\n",
    "    foreground[blue_mask > 0] = 0\n",
    "    return (foreground * 255).astype(np.uint8)\n",
    "\n",
    "def expand_head_region_and_get_body(segmentation_map, face_mask, expansion_factor=1.2):\n",
    "    y, x = np.where(face_mask)\n",
    "    if len(y) == 0 or len(x) == 0:\n",
    "        return segmentation_map, np.zeros_like(segmentation_map)\n",
    "    top, bottom, left, right = y.min(), y.max(), x.min(), x.max()\n",
    "    center_y, center_x = (top + bottom) // 2, (left + right) // 2\n",
    "    new_height, new_width = int((bottom - top) * expansion_factor), int((right - left) * expansion_factor)\n",
    "    new_top = max(0, center_y - new_height // 2)\n",
    "    new_bottom = min(segmentation_map.shape[0], center_y + new_height // 2)\n",
    "    new_left = max(0, center_x - new_width // 2)\n",
    "    new_right = min(segmentation_map.shape[1], center_x + new_width // 2)\n",
    "    head_mask = np.zeros_like(segmentation_map)\n",
    "    head_mask[new_top:new_bottom, new_left:new_right] = 1\n",
    "    expanded_head = segmentation_map.copy()\n",
    "    expanded_head[new_top:new_bottom, new_left:new_right] = 1\n",
    "    body_mask = np.logical_and(segmentation_map == 1, head_mask == 0)\n",
    "    return expanded_head, body_mask.astype(np.float32), head_mask.astype(np.float32)\n",
    "\n",
    "def detect_face(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    face_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(face_mask, (x, y), (x+w, y+h), 255, -1)\n",
    "    return face_mask\n",
    "\n",
    "def initial_segmentation(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "def post_process_segmentation(segmented_image, segmentation_map, face_mask):\n",
    "    _, binary_mask = cv2.threshold(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    binary_mask = cv2.morphologyEx(cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel, iterations=3), cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    segmentation_map = segmentation_map * (binary_mask > 0)\n",
    "    segmentation_map = cv2.morphologyEx(segmentation_map, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    y, x = np.where(face_mask > 0)\n",
    "    if len(y) > 0 and len(x) > 0:\n",
    "        top, bottom, left, right = y.min(), y.max(), x.min(), x.max()\n",
    "        eye_y, eye_height = top + (bottom - top) // 3, (bottom - top) // 4\n",
    "        eye_mask = np.zeros_like(segmentation_map)\n",
    "        eye_mask[eye_y:eye_y+eye_height, left:right] = 255\n",
    "        segmentation_map[eye_mask > 0] = cv2.dilate(segmentation_map, kernel, iterations=2)[eye_mask > 0]\n",
    "    segmented_image = segmented_image.copy()\n",
    "    segmented_image[segmentation_map == 0] = [0, 0, 0]\n",
    "    return segmented_image, segmentation_map\n",
    "\n",
    "# Main process\n",
    "face_mask = detect_face(grow_cut_rgb)\n",
    "initial_seg = initial_segmentation(grow_cut_rgb)\n",
    "final_segmentation = cv2.morphologyEx(cv2.morphologyEx(initial_seg, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8), iterations=2), cv2.MORPH_OPEN, np.ones((5,5), np.uint8), iterations=1)\n",
    "final_segmented_image, final_segmentation = post_process_segmentation(grow_cut_rgb, final_segmentation, face_mask)\n",
    "\n",
    "feet_height = int(final_segmentation.shape[0] * 0.1)\n",
    "feet_mask = np.zeros_like(final_segmentation)\n",
    "feet_mask[-feet_height:, :] = final_segmentation[-feet_height:, :]\n",
    "feet_image = grow_cut_rgb.copy()\n",
    "feet_image[feet_mask == 0] = [0, 0, 0]\n",
    "\n",
    "refined_trimap, final_segmentation = refine_trimap_and_segment(learned_alpha, initial_trimap, face_mask)\n",
    "final_segmentation, body_mask, head_mask = expand_head_region_and_get_body(final_segmentation, face_mask)\n",
    "refined_body_segmentation = refine_segmentation(final_segmentation, grow_cut_rgb, body_mask)\n",
    "refined_full_segmentation = refined_body_segmentation.copy()\n",
    "refined_full_segmentation[head_mask == 1] = grow_cut_rgb[head_mask == 1]\n",
    "\n",
    "combined_foreground = refined_full_segmentation.copy()\n",
    "combined_foreground[-feet_height:, :] = feet_image[-feet_height:, :]\n",
    "\n",
    "final_segmentation_map = np.zeros((combined_foreground.shape[0], combined_foreground.shape[1]), dtype=np.uint8)\n",
    "final_segmentation_map[np.any(combined_foreground != [0, 0, 0], axis=-1)] = 255\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Final Segmentation Map\", final_segmentation_map)\n",
    "cv2.imshow(\"Combined Foreground\", combined_foreground)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix holes in segmentation map\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "closed_map = cv2.morphologyEx(final_segmentation_map, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Flood fill to fill holes\n",
    "flood_map = closed_map.copy()\n",
    "cv2.floodFill(flood_map, None, (0,0), 255)\n",
    "holes_filled = cv2.bitwise_not(flood_map)\n",
    "fixed_map = cv2.bitwise_or(closed_map, holes_filled)\n",
    "\n",
    "# Fix top head region\n",
    "top_expansion = 5\n",
    "fixed_map[:top_expansion, :] = 255\n",
    "\n",
    "# Implement fixed map to combined foreground\n",
    "mask = cv2.cvtColor(fixed_map, cv2.COLOR_GRAY2BGR)\n",
    "fixed_foreground = cv2.bitwise_and(combined_foreground, mask)\n",
    "\n",
    "# Display result\n",
    "cv2.imshow(\"Fixed Segmentation Map\", fixed_map)\n",
    "cv2.imshow(\"Fixed Combined Foreground\", fixed_foreground)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save Result\n",
    "cv2.imwrite(\"fixed_segmentation_map.png\", fixed_map)\n",
    "cv2.imwrite(\"fixed_combined_foreground.png\", fixed_foreground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an image for the new background:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose image\n",
    "def choose_image():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    return file_path\n",
    "\n",
    "# Read fixed foreground and segmentation map\n",
    "fixed_foreground = cv2.imread(\"fixed_combined_foreground.png\")\n",
    "fixed_map = cv2.imread(\"fixed_segmentation_map.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Choose new background\n",
    "print(\"Choose an image for the new background:\")\n",
    "background_path = choose_image()\n",
    "new_background = cv2.imread(background_path)\n",
    "\n",
    "# Ensure the background size matches the foreground\n",
    "if new_background.shape[:2] != fixed_foreground.shape[:2]:\n",
    "    new_background = cv2.resize(new_background, (fixed_foreground.shape[1], fixed_foreground.shape[0]))\n",
    "\n",
    "# Create mask from segmentation map\n",
    "mask = fixed_map\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the foreground and background\n",
    "fg = cv2.bitwise_and(fixed_foreground, fixed_foreground, mask=mask)\n",
    "bg = cv2.bitwise_and(new_background, new_background, mask=mask_inv)\n",
    "\n",
    "# Combine foreground and background\n",
    "result = cv2.add(fg, bg)\n",
    "\n",
    "# Display result\n",
    "cv2.imshow(\"Original Foreground\", fixed_foreground)\n",
    "cv2.imshow(\"New Background\", new_background)\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Simpan hasil\n",
    "cv2.imwrite(\"result_with_new_background.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code cell 1:\n",
      "%pip install opencv-python numpy scipy scikit-image matplotlib\n",
      "%pip install matplotlib\n",
      "%pip install tensorflow\n",
      "%pip install torch torchvision\n",
      "%pip install mediapipe\n",
      "%pip install nbformat\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 2:\n",
      "import cv2\n",
      "import numpy as np\n",
      "import time\n",
      "from scipy.ndimage import label, find_objects, median_filter, shift, distance_transform_edt\n",
      "from scipy.sparse import csr_matrix, diags\n",
      "from scipy.sparse.linalg import spsolve\n",
      "from skimage import morphology, measure\n",
      "from skimage.segmentation import slic\n",
      "from skimage.color import rgb2gray\n",
      "from pathlib import Path\n",
      "import matplotlib.pyplot as plt\n",
      "from tkinter import filedialog, Tk, simpledialog, messagebox\n",
      "\n",
      "print(cv2.__version__)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 3:\n",
      "root = Tk()\n",
      "root.withdraw()\n",
      "\n",
      "def browse_video():\n",
      "    Tk().withdraw() \n",
      "    filename = filedialog.askopenfilename() \n",
      "    return filename\n",
      "\n",
      "# Choose Frame\n",
      "def browse_frame(cap, total_frames):\n",
      "    frame_number = simpledialog.askinteger(\"Choose Frame\", f\"Enter frame number (1 to {total_frames}):\")\n",
      "    if frame_number is not None and 1 <= frame_number <= total_frames:\n",
      "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
      "        ret, frame = cap.read() \n",
      "        if not ret:\n",
      "            print(\"Error: Unable to read frame.\")\n",
      "            return None\n",
      "        return frame\n",
      "    else:\n",
      "        messagebox.showwarning(\"Invalid Frame\", \"Please enter a valid frame number.\")\n",
      "        return None\n",
      "\n",
      "# Input RGB Video\n",
      "RGB_video_path = browse_video()\n",
      "if RGB_video_path:\n",
      "    cap_rgb = cv2.VideoCapture(RGB_video_path)\n",
      "    if not cap_rgb.isOpened():\n",
      "        print(\"Error: Unable to open RGB video.\")\n",
      "    else:\n",
      "        total_frames_rgb = int(cap_rgb.get(cv2.CAP_PROP_FRAME_COUNT))\n",
      "        print(\"RGB Video selected:\", RGB_video_path)\n",
      "        rgb_frame = browse_frame(cap_rgb, total_frames_rgb)  # Memilih frame dari video RGB\n",
      "        if rgb_frame is not None:\n",
      "            cv2.imshow('Original RGB Frame', rgb_frame)\n",
      "            cv2.waitKey(0)\n",
      "            cv2.destroyAllWindows()\n",
      "            \n",
      "\n",
      "# Input Depth Video\n",
      "Depth_video_path = browse_video()\n",
      "if Depth_video_path:\n",
      "    cap_depth = cv2.VideoCapture(Depth_video_path)\n",
      "    if not cap_depth.isOpened():\n",
      "        print(\"Error: Unable to open Depth video.\")\n",
      "    else:\n",
      "        total_frames_depth = int(cap_depth.get(cv2.CAP_PROP_FRAME_COUNT))\n",
      "        print(\"Depth Video selected:\", Depth_video_path)\n",
      "        depth_frame = browse_frame(cap_depth, total_frames_depth)  # Memilih frame dari video Depth\n",
      "        if depth_frame is not None:\n",
      "            cv2.imshow('Original Depth Frame', depth_frame)\n",
      "            cv2.waitKey(0)\n",
      "            cv2.destroyAllWindows()\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 4:\n",
      "# Depth Processing\n",
      "def depth_processing(depth_frame):\n",
      "    if depth_frame is None:\n",
      "        print(\"Error: Depth frame is None.\")\n",
      "        return None\n",
      "    \n",
      "    # Thresholding operations\n",
      "    lower_threshold = 45\n",
      "    upper_threshold = 85\n",
      "    processed_depth = np.zeros_like(depth_frame)\n",
      "    processed_depth[(depth_frame > lower_threshold) & (depth_frame < upper_threshold)] = 255\n",
      "    return processed_depth\n",
      "\n",
      "processed_depth = depth_processing(depth_frame)\n",
      "\n",
      "if processed_depth is not None:\n",
      "    cv2.imshow('Depth Processing', processed_depth)\n",
      "    cv2.waitKey(0)\n",
      "    cv2.destroyAllWindows()\n",
      "else:\n",
      "    print(\"Error in depth processing.\")\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 5:\n",
      "# RGB processing\n",
      "def depth_processing(depth_frame):\n",
      "    if depth_frame is None:\n",
      "        print(\"Error: Depth frame is None.\")\n",
      "        return None\n",
      "\n",
      "    depth_values = depth_frame.ravel()\n",
      "    depth_values = depth_values[depth_values != 0]\n",
      "    lower_threshold = np.percentile(depth_values, 5)\n",
      "    upper_threshold = np.percentile(depth_values, 68)\n",
      "\n",
      "    depth_enh = np.zeros_like(depth_frame, dtype=np.uint8)\n",
      "    depth_enh[(depth_frame > lower_threshold) & (depth_frame < upper_threshold)] = 255\n",
      "\n",
      "    # Morphological operations to refine the mask\n",
      "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
      "    depth_enh = cv2.erode(depth_enh, kernel, iterations=2)\n",
      "    depth_enh = cv2.dilate(depth_enh, kernel, iterations=2)\n",
      "\n",
      "    return depth_enh\n",
      "\n",
      "def rgb_processing(rgb_frame, depth_enh):\n",
      "    if rgb_frame is None or depth_enh is None:\n",
      "        print(\"Error: RGB frame or depth enhancement is None.\")\n",
      "        return None\n",
      "\n",
      "    human_region_mask = depth_enh.astype(bool)\n",
      "    human_region = rgb_frame.copy()\n",
      "    human_region[~human_region_mask] = 0\n",
      "\n",
      "    return human_region\n",
      "\n",
      "processed_depth = depth_processing(depth_frame)\n",
      "human_region = rgb_processing(rgb_frame, processed_depth)\n",
      "\n",
      "if human_region is not None:\n",
      "    cv2.imshow('Human Region', human_region)\n",
      "    cv2.waitKey(0)\n",
      "    cv2.destroyAllWindows()\n",
      "else:\n",
      "    print(\"Error in processing.\")\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 6:\n",
      "def detect_faces(image):\n",
      "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
      "    return faces\n",
      "\n",
      "# Function for hair region restoration using GrabCut\n",
      "def restore_hair_region(rgb_frame, human_region):\n",
      "    faces = detect_faces(human_region)\n",
      "    if len(faces) > 0:\n",
      "        x, y, w, h = faces[0]\n",
      "\n",
      "        x1 = max(0, x - int(0.2 * w))\n",
      "        y1 = max(0, y - int(0.2 * h))\n",
      "        x2 = min(rgb_frame.shape[1], x + int(1.2 * w))\n",
      "        y2 = min(rgb_frame.shape[0], y + int(1.2 * h))\n",
      "\n",
      "        mask = np.zeros((rgb_frame.shape[0], rgb_frame.shape[1]), dtype=np.uint8)\n",
      "        rect = (x1, y1, x2 - x1, y2 - y1)\n",
      "        bgdModel = np.zeros((1, 65), np.float64)\n",
      "        fgdModel = np.zeros((1, 65), np.float64)\n",
      "        cv2.grabCut(rgb_frame, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
      "\n",
      "        hair_mask = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
      "\n",
      "        enhanced_region = np.zeros_like(rgb_frame)\n",
      "        enhanced_region[human_region > 0] = rgb_frame[human_region > 0]\n",
      "        enhanced_region[hair_mask > 0] = rgb_frame[hair_mask > 0]\n",
      "\n",
      "        return enhanced_region\n",
      "    else:\n",
      "        return human_region\n",
      "\n",
      "processed_depth = depth_processing(depth_frame)\n",
      "human_region = rgb_processing(rgb_frame, processed_depth)\n",
      "enhanced_region = restore_hair_region(rgb_frame, human_region)\n",
      "\n",
      "# Display result\n",
      "if enhanced_region is not None:\n",
      "    cv2.imshow('Enhanced Human Region', enhanced_region)\n",
      "    cv2.waitKey(0)\n",
      "    cv2.destroyAllWindows()\n",
      "else:\n",
      "    print(\"Error in processing.\")\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 7:\n",
      "def detect_faces(image):\n",
      "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
      "    return faces\n",
      "\n",
      "def get_hair_region(x, y, w, h, image_shape):\n",
      "    # Define the hair area above the face\n",
      "    x1 = x\n",
      "    y1 = max(0, y - int(0.5 * h))\n",
      "    x2 = x + w\n",
      "    y2 = y\n",
      "    return x1, y1, x2, y2\n",
      "\n",
      "def downsample_image(image, scale):\n",
      "    width = int(image.shape[1] * scale)\n",
      "    height = int(image.shape[0] * scale)\n",
      "    return cv2.resize(image, (width, height))\n",
      "\n",
      "def growcut(image, labels, max_iterations=100):\n",
      "    height, width = labels.shape\n",
      "    strength = np.zeros((height, width), dtype=np.float32)\n",
      "    strength[labels != 0] = 1.0\n",
      "\n",
      "    for iteration in range(max_iterations):\n",
      "        old_labels = labels.copy()\n",
      "        for y in range(1, height-1):\n",
      "            for x in range(1, width-1):\n",
      "                if labels[y, x] == 0:\n",
      "                    continue\n",
      "                neighborhood = [(y-1, x), (y+1, x), (y, x-1), (y, x+1), (y-1, x-1), (y-1, x+1), (y+1, x-1), (y+1, x+1)]\n",
      "                for ny, nx in neighborhood:\n",
      "                    if ny < 0 or ny >= height or nx < 0 or nx >= width:\n",
      "                        continue\n",
      "                    if labels[ny, nx] == 0:\n",
      "                        continue\n",
      "                    dist = np.linalg.norm(image[y, x] - image[ny, nx])\n",
      "                    strength_factor = 1 - dist / 255.0\n",
      "                    if strength_factor * strength[ny, nx] > strength[y, x]:\n",
      "                        strength[y, x] = strength_factor * strength[ny, nx]\n",
      "                        labels[y, x] = labels[ny, nx]\n",
      "        if np.array_equal(labels, old_labels):\n",
      "            break\n",
      "\n",
      "    return labels\n",
      "\n",
      "def growcut_segmentation(enhanced_region, processed_depth):\n",
      "    gray_depth = cv2.cvtColor(processed_depth, cv2.COLOR_BGR2GRAY)\n",
      "    _, depth_mask = cv2.threshold(gray_depth, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
      "\n",
      "    faces = detect_faces(enhanced_region)  \n",
      "    \n",
      "    hair_mask = np.zeros_like(gray_depth, dtype=np.uint8)\n",
      "    for x, y, w, h in faces:\n",
      "        x1, y1, x2, y2 = get_hair_region(x, y, w, h, enhanced_region.shape)\n",
      "        cv2.rectangle(hair_mask, (x1, y1), (x2, y2), 255, -1)\n",
      "\n",
      "    fg_mask_init = cv2.bitwise_or(depth_mask, hair_mask)\n",
      "\n",
      "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
      "    fg_mask = cv2.morphologyEx(fg_mask_init, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
      "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
      "\n",
      "    height, width = gray_depth.shape\n",
      "    labels = np.zeros((height, width), dtype=np.int32)\n",
      "    labels[fg_mask == 255] = 1\n",
      "    labels[depth_mask == 0] = -1\n",
      "\n",
      "    small_region = downsample_image(enhanced_region, 0.5)\n",
      "    small_depth = downsample_image(processed_depth, 0.5)\n",
      "    small_labels = cv2.resize(labels, (labels.shape[1] // 2, labels.shape[0] // 2), interpolation=cv2.INTER_NEAREST)\n",
      "\n",
      "    print(\"Performing GrowCut segmentation...\")\n",
      "    labels_out = growcut(small_region, small_labels)\n",
      "    labels_out = cv2.medianBlur(labels_out.astype(np.float32), 3)\n",
      "    labels_out = cv2.resize(labels_out, (labels.shape[1], labels.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
      "    grow_cut_rgb = np.repeat(labels_out[:, :, np.newaxis], 3, axis=2).astype(np.uint8) * enhanced_region\n",
      "    \n",
      "    # Obtain mask for hair\n",
      "    hair_mask = labels_out.copy()\n",
      "    hair_mask[hair_mask != 1] = 0  # Set all values other than 1 to 0\n",
      "\n",
      "    # Obtain mask for the body (excluding hair)\n",
      "    body_mask = labels_out.copy()\n",
      "    body_mask[body_mask == 1] = 0  # Set all values of 1 to 0\n",
      "    body_mask[body_mask == -1] = 1  # Set all values of -1 to 1\n",
      "\n",
      "    # Combine GrowCut segmentation result with original color for hair\n",
      "    grow_cut_rgb = np.zeros_like(enhanced_region)\n",
      "    grow_cut_rgb[body_mask.astype(bool)] = enhanced_region[body_mask.astype(bool)]\n",
      "    grow_cut_rgb[hair_mask.astype(bool)] = enhanced_region[hair_mask.astype(bool)]\n",
      "\n",
      "    return labels_out, grow_cut_rgb\n",
      "\n",
      "start_time = time.time()\n",
      "labels_out, grow_cut_rgb = growcut_segmentation(enhanced_region, processed_depth)\n",
      "end_time = time.time()\n",
      "\n",
      "print(f\"GrowCut Segmentation Time: {end_time - start_time} seconds\")\n",
      "\n",
      "# Tampilkan hasil segmentasi\n",
      "cv2.imshow(\"The result of GrowCut segmentation\", grow_cut_rgb)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 8:\n",
      "def generate_trimap(labels, kernel_size=5, erosion_iterations=1, dilation_iterations=2):\n",
      "    \"\"\"\n",
      "    Generate a trimap from the segmentation labels.\n",
      "    \"\"\"\n",
      "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
      "    \n",
      "    # Define the foreground and background\n",
      "    foreground = (labels == 1).astype(np.uint8)\n",
      "    background = (labels == -1).astype(np.uint8)\n",
      "\n",
      "    # Erode the foreground to get the definite foreground\n",
      "    eroded_foreground = cv2.erode(foreground, kernel, iterations=erosion_iterations)\n",
      "\n",
      "    # Dilate the foreground to get the uncertain region\n",
      "    dilated_foreground = cv2.dilate(foreground, kernel, iterations=dilation_iterations)\n",
      "\n",
      "    # Initialize the trimap with background (0)\n",
      "    trimap = np.zeros_like(labels, dtype=np.uint8)\n",
      "    \n",
      "    # Assign definite foreground (255)\n",
      "    trimap[eroded_foreground == 1] = 255\n",
      "    \n",
      "    # Assign uncertain region (128)\n",
      "    trimap[(dilated_foreground == 1) & (eroded_foreground == 0)] = 128\n",
      "    \n",
      "    return trimap\n",
      "\n",
      "start_time = time.time()\n",
      "labels_out, grow_cut_rgb = growcut_segmentation(enhanced_region, processed_depth)\n",
      "trimap = generate_trimap(labels_out)\n",
      "end_time = time.time()\n",
      "\n",
      "print(f\"Trimap Generation Time: {end_time - start_time} seconds\")\n",
      "\n",
      "# Display segmentation result and trimap\n",
      "cv2.imshow(\"Trimap\", trimap)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 9:\n",
      "def generate_new_trimap(alpha, erosion_size=3, dilation_size=3):\n",
      "    kernel_erosion = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erosion_size, erosion_size))\n",
      "    kernel_dilation = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_size, dilation_size))\n",
      "\n",
      "    foreground = (alpha > 0.8).astype(np.uint8)\n",
      "    background = (alpha < 0.2).astype(np.uint8)\n",
      "\n",
      "    eroded_foreground = cv2.erode(foreground, kernel_erosion)\n",
      "    dilated_background = cv2.dilate(background, kernel_dilation)\n",
      "\n",
      "    new_trimap = np.full(alpha.shape, 128, dtype=np.uint8)\n",
      "    new_trimap[eroded_foreground == 1] = 255\n",
      "    new_trimap[dilated_background == 1] = 0\n",
      "\n",
      "    return new_trimap\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 10:\n",
      "def closed_form_matting(image, trimap, epsilon=1e-7, win_size=1):\n",
      "    # Convert image to float and normalize\n",
      "    image = image.astype(np.float64) / 255.0\n",
      "    \n",
      "    # Get trimap regions\n",
      "    is_fg = (trimap == 255)\n",
      "    is_bg = (trimap == 0)\n",
      "    is_unknown = (trimap == 128)\n",
      "\n",
      "    # Compute Matting Laplacian\n",
      "    h, w = trimap.shape\n",
      "    win_radius = win_size // 2\n",
      "    win_area = (win_size * 2 + 1) ** 2\n",
      "    \n",
      "    indices = np.arange(h * w).reshape(h, w)\n",
      "    L_data, L_rows, L_cols = [], [], []\n",
      "\n",
      "    for y in range(h):\n",
      "        for x in range(w):\n",
      "            if is_unknown[y, x]:\n",
      "                window = image[max(0, y-win_radius):min(h, y+win_radius+1),\n",
      "                               max(0, x-win_radius):min(w, x+win_radius+1)]\n",
      "                win_indices = indices[max(0, y-win_radius):min(h, y+win_radius+1),\n",
      "                                      max(0, x-win_radius):min(w, x+win_radius+1)]\n",
      "                \n",
      "                mean = np.mean(window, axis=(0, 1))\n",
      "                cov = np.cov(window.reshape(-1, 3).T)\n",
      "                \n",
      "                inv_cov = np.linalg.inv(cov + (epsilon / win_area) * np.eye(3))\n",
      "                \n",
      "                for wy in range(window.shape[0]):\n",
      "                    for wx in range(window.shape[1]):\n",
      "                        w_idx = win_indices[wy, wx]\n",
      "                        if w_idx != indices[y, x]:\n",
      "                            diff = window[wy, wx] - mean\n",
      "                            L_data.append(1 + diff.dot(inv_cov).dot(diff))\n",
      "                            L_rows.append(indices[y, x])\n",
      "                            L_cols.append(w_idx)\n",
      "    \n",
      "    L = csr_matrix((L_data, (L_rows, L_cols)), shape=(h*w, h*w))\n",
      "    L = L + L.T - diags(L.sum(axis=1).A.ravel())\n",
      "    \n",
      "    # Solve for alpha\n",
      "    b = np.zeros(h * w)\n",
      "    b[is_fg.ravel()] = 1\n",
      "    b[is_bg.ravel()] = 0\n",
      "\n",
      "    x = spsolve(L + diags([1e-5] * (h*w)), b)\n",
      "    alpha = np.clip(x.reshape(h, w), 0, 1)\n",
      "    \n",
      "    return alpha\n",
      "\n",
      "start_time = time.time()\n",
      "\n",
      "# Initial trimap generation\n",
      "initial_trimap = generate_trimap(labels_out)\n",
      "\n",
      "# Closed Form Matting\n",
      "alpha_matte = closed_form_matting(grow_cut_rgb, initial_trimap)\n",
      "\n",
      "# Generate new trimap based on refined alpha matte\n",
      "new_trimap = generate_new_trimap(alpha_matte)\n",
      "\n",
      "end_time = time.time()\n",
      "\n",
      "print(f\"Total Processing Time: {end_time - start_time} seconds\")\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Original Image\", grow_cut_rgb)\n",
      "cv2.imshow(\"Initial Trimap\", initial_trimap)\n",
      "cv2.imshow(\"Alpha Matte\", alpha_matte)\n",
      "cv2.imshow(\"New Trimap\", new_trimap)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# # Save results for further analysis\n",
      "# cv2.imwrite(\"initial_trimap.png\", initial_trimap)\n",
      "# cv2.imwrite(\"alpha_matte.png\", (alpha_matte * 255).astype(np.uint8))\n",
      "# cv2.imwrite(\"new_trimap.png\", new_trimap)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 11:\n",
      "def learned_based_matting(image, trimap, alpha_initial, window_size=7, c=1.0):\n",
      "    h, w = trimap.shape\n",
      "    n = h * w\n",
      "    \n",
      "    # Create neighborhood matrix\n",
      "    def get_neighbors(i, j):\n",
      "        neighbors = []\n",
      "        for di in range(-window_size//2, window_size//2 + 1):\n",
      "            for dj in range(-window_size//2, window_size//2 + 1):\n",
      "                if 0 <= i + di < h and 0 <= j + dj < w:\n",
      "                    neighbors.append((i + di) * w + (j + dj))\n",
      "        return neighbors\n",
      "\n",
      "    # Construct F matrix\n",
      "    F_data, F_row, F_col = [], [], []\n",
      "    for i in range(h):\n",
      "        for j in range(w):\n",
      "            if trimap[i, j] == 128:  # Unknown region\n",
      "                neighbors = get_neighbors(i, j)\n",
      "                weights = np.ones(len(neighbors)) / len(neighbors)  # Simple average weights\n",
      "                for k, neighbor in enumerate(neighbors):\n",
      "                    F_data.append(weights[k])\n",
      "                    F_row.append(i * w + j)\n",
      "                    F_col.append(neighbor)\n",
      "\n",
      "    F = csr_matrix((F_data, (F_row, F_col)), shape=(n, n))\n",
      "\n",
      "    # Construct identity matrix for known pixels\n",
      "    I_known = diags([1 if trimap.flatten()[i] != 128 else 0 for i in range(n)])\n",
      "\n",
      "    # Solve the quadratic cost equation\n",
      "    A = diags([1] * n) - F.T\n",
      "    b = c * I_known * alpha_initial.flatten()\n",
      "\n",
      "    alpha_refined = spsolve(A.T @ A + c * I_known, A.T @ b)\n",
      "    alpha_refined = np.clip(alpha_refined.reshape(h, w), 0, 1)\n",
      "\n",
      "    return alpha_refined\n",
      "\n",
      "# Usage\n",
      "start_time = time.time()\n",
      "\n",
      "learned_alpha = learned_based_matting(grow_cut_rgb, initial_trimap, alpha_matte)\n",
      "\n",
      "end_time = time.time()\n",
      "print(f\"Learned-Based Matting Time: {end_time - start_time} seconds\")\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Original Image\", grow_cut_rgb)\n",
      "cv2.imshow(\"Initial Alpha Matte\", alpha_matte)\n",
      "cv2.imshow(\"Learned-Based Alpha Matte\", learned_alpha)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Save results\n",
      "# cv2.imwrite(\"learned_alpha_matte.png\", (learned_alpha * 255).astype(np.uint8))\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 12:\n",
      "def increase_resolution(image, scale_factor=2):\n",
      "    return cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
      "\n",
      "rgb_frame = increase_resolution(rgb_frame)\n",
      "depth_frame = increase_resolution(depth_frame)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 13:\n",
      "def detect_face(image):\n",
      "    # Load the pre-trained face detector\n",
      "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "    \n",
      "    # Convert image to grayscale\n",
      "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "    \n",
      "    # Detect faces\n",
      "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "    \n",
      "    # Create a mask\n",
      "    face_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
      "    \n",
      "    # Draw rectangles around the faces on the mask\n",
      "    for (x, y, w, h) in faces:\n",
      "        cv2.rectangle(face_mask, (x, y), (x+w, y+h), 255, -1)\n",
      "    \n",
      "    return face_mask\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 14:\n",
      "def refine_trimap_and_segment(alpha_matte, original_trimap, face_mask, threshold_low=0.1, threshold_high=0.9, face_threshold_low=0.05, face_threshold_high=0.8):\n",
      "    refined_trimap = np.zeros_like(original_trimap)\n",
      "    \n",
      "    # Apply different thresholds for face area\n",
      "    refined_trimap[face_mask & (alpha_matte <= face_threshold_low)] = 0\n",
      "    refined_trimap[face_mask & (alpha_matte >= face_threshold_high)] = 255\n",
      "    refined_trimap[face_mask & (alpha_matte > face_threshold_low) & (alpha_matte < face_threshold_high)] = 128\n",
      "    \n",
      "    # Apply normal thresholds for the rest of the body\n",
      "    body_mask = ~face_mask.astype(bool)\n",
      "    refined_trimap[body_mask & (alpha_matte <= threshold_low)] = 0\n",
      "    refined_trimap[body_mask & (alpha_matte >= threshold_high)] = 255\n",
      "    refined_trimap[body_mask & (alpha_matte > threshold_low) & (alpha_matte < threshold_high)] = 128\n",
      "\n",
      "    # Create final segmentation map\n",
      "    segmentation_map = np.zeros_like(alpha_matte)\n",
      "    segmentation_map[alpha_matte >= 0.5] = 1\n",
      "    \n",
      "    return refined_trimap, segmentation_map\n",
      "\n",
      "def expand_head_region(segmentation_map, face_mask, expansion_factor=1.2):\n",
      "    # Calculate bounding box of face region\n",
      "    y, x = np.where(face_mask)\n",
      "    if len(y) == 0 or len(x) == 0:  # No face detected\n",
      "        return segmentation_map\n",
      "    \n",
      "    top, bottom, left, right = y.min(), y.max(), x.min(), x.max()\n",
      "    \n",
      "    # Expand bounding box\n",
      "    height = bottom - top\n",
      "    width = right - left\n",
      "    center_y, center_x = (top + bottom) // 2, (left + right) // 2\n",
      "    new_height = int(height * expansion_factor)\n",
      "    new_width = int(width * expansion_factor)\n",
      "    \n",
      "    new_top = max(0, center_y - new_height // 2)\n",
      "    new_bottom = min(segmentation_map.shape[0], center_y + new_height // 2)\n",
      "    new_left = max(0, center_x - new_width // 2)\n",
      "    new_right = min(segmentation_map.shape[1], center_x + new_width // 2)\n",
      "    \n",
      "    # Expand segmentation in the new bounding box\n",
      "    segmentation_map[new_top:new_bottom, new_left:new_right] = 1\n",
      "    \n",
      "    # # Tambahkan operasi dilasi\n",
      "    # kernel = np.ones((5,5), np.uint8)\n",
      "    # segmentation_map = cv2.dilate(segmentation_map.astype(np.uint8), kernel, iterations=2)\n",
      "   \n",
      "   \n",
      "    return segmentation_map\n",
      "\n",
      "def apply_segmentation(image, segmentation_map):\n",
      "    segmented_image = image.copy()\n",
      "    segmented_image[segmentation_map == 0] = [0, 0, 0]  # Set background to black\n",
      "    return segmented_image\n",
      "\n",
      "# Create face mask\n",
      "face_mask = detect_face(grow_cut_rgb)\n",
      "\n",
      "# Refine trimap and create segmentation\n",
      "refined_trimap, final_segmentation = refine_trimap_and_segment(learned_alpha, initial_trimap, face_mask)\n",
      "\n",
      "# Expand head region\n",
      "final_segmentation = expand_head_region(final_segmentation, face_mask)\n",
      "\n",
      "# Apply the final segmentation to the original image\n",
      "final_segmented_image = apply_segmentation(grow_cut_rgb, final_segmentation)\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Refined Trimap\", refined_trimap)\n",
      "cv2.imshow(\"Final Segmentation Map\", final_segmentation.astype(np.float32))\n",
      "cv2.imshow(\"Final Segmented Image\", final_segmented_image)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Print some statistics\n",
      "unknown_pixels_original = np.sum(initial_trimap == 128)\n",
      "unknown_pixels_refined = np.sum(refined_trimap == 128)\n",
      "print(f\"Unknown pixels in original trimap: {unknown_pixels_original}\")\n",
      "print(f\"Unknown pixels in refined trimap: {unknown_pixels_refined}\")\n",
      "print(f\"Reduction in unknown pixels: {unknown_pixels_original - unknown_pixels_refined}\")\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 15:\n",
      "# Baca segmentation map dan combined foreground\n",
      "segmentation_map = cv2.imread(\"final_segmentation_map.png\", cv2.IMREAD_GRAYSCALE)\n",
      "combined_foreground = cv2.imread(\"combined_foreground.png\")\n",
      "\n",
      "# Perbaiki lubang pada segmentation map\n",
      "kernel = np.ones((5,5), np.uint8)\n",
      "closed_map = cv2.morphologyEx(segmentation_map, cv2.MORPH_CLOSE, kernel)\n",
      "\n",
      "# Flood fill untuk menutup lubang besar\n",
      "flood_map = closed_map.copy()\n",
      "cv2.floodFill(flood_map, None, (0,0), 255)\n",
      "holes_filled = cv2.bitwise_not(flood_map)\n",
      "fixed_map = cv2.bitwise_or(closed_map, holes_filled)\n",
      "\n",
      "# Perbaiki bagian atas kepala\n",
      "top_expansion = 5\n",
      "fixed_map[:top_expansion, :] = 255\n",
      "\n",
      "# Terapkan fixed map ke combined foreground\n",
      "mask = cv2.cvtColor(fixed_map, cv2.COLOR_GRAY2BGR)\n",
      "fixed_foreground = cv2.bitwise_and(combined_foreground, mask)\n",
      "\n",
      "# Simpan hasil\n",
      "cv2.imwrite(\"fixed_segmentation_map.png\", fixed_map)\n",
      "cv2.imwrite(\"fixed_combined_foreground.png\", fixed_foreground)\n",
      "\n",
      "# Tampilkan hasil\n",
      "cv2.imshow(\"Fixed Segmentation Map\", fixed_map)\n",
      "cv2.imshow(\"Fixed Combined Foreground\", fixed_foreground)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 16:\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "def color_decontamination(image, mask):\n",
      "    # Convert to float\n",
      "    image = image.astype(np.float32) / 255.0\n",
      "    \n",
      "    # Calculate the average color of the background\n",
      "    bg_color = image[mask == 0].mean(axis=0)\n",
      "    \n",
      "    # Subtract the background color from the image\n",
      "    decontaminated = image - bg_color\n",
      "    \n",
      "    # Clip values to [0, 1] range\n",
      "    decontaminated = np.clip(decontaminated, 0, 1)\n",
      "    \n",
      "    # Convert back to uint8\n",
      "    return (decontaminated * 255).astype(np.uint8)\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread(\"fixed_combined_foreground.png\")\n",
      "\n",
      "# Create a binary mask\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "_, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
      "\n",
      "# Apply color decontamination\n",
      "decontaminated = color_decontamination(img, mask)\n",
      "\n",
      "# Apply inpainting to fix artifacts\n",
      "inpainted = cv2.inpaint(decontaminated, 255 - mask, 3, cv2.INPAINT_TELEA)\n",
      "\n",
      "# Combine the results\n",
      "result = cv2.bitwise_and(inpainted, inpainted, mask=mask)\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Original\", img)\n",
      "cv2.imshow(\"Decontaminated\", decontaminated)\n",
      "cv2.imshow(\"Inpainted\", inpainted)\n",
      "cv2.imshow(\"Final Result\", result)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Save the result\n",
      "cv2.imwrite(\"refined_foreground_decontamination.png\", result)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 17:\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "def color_decontamination(image, mask):\n",
      "    image = image.astype(np.float32) / 255.0\n",
      "    bg_color = image[mask == 0].mean(axis=0)\n",
      "    decontaminated = image - bg_color\n",
      "    decontaminated = np.clip(decontaminated, 0, 1)\n",
      "    return (decontaminated * 255).astype(np.uint8)\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread(\"fixed_combined_foreground.png\")\n",
      "\n",
      "# Create a binary mask\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "_, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
      "\n",
      "# Apply color decontamination\n",
      "decontaminated = color_decontamination(img, mask)\n",
      "\n",
      "# Apply inpainting to fix artifacts\n",
      "inpainted = cv2.inpaint(decontaminated, 255 - mask, 3, cv2.INPAINT_TELEA)\n",
      "\n",
      "# Extract only the foreground from the inpainted result\n",
      "foreground_only = cv2.bitwise_and(inpainted, inpainted, mask=mask)\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Original\", img)\n",
      "cv2.imshow(\"Inpainted\", inpainted)\n",
      "cv2.imshow(\"Foreground Only\", foreground_only)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Save the result\n",
      "cv2.imwrite(\"foreground_only_inpainted.png\", foreground_only)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 18:\n",
      "\n",
      "def color_decontamination(image, mask):\n",
      "    image = image.astype(np.float32) / 255.0\n",
      "    bg_color = image[mask == 0].mean(axis=0)\n",
      "    decontaminated = image - bg_color\n",
      "    decontaminated = np.clip(decontaminated, 0, 1)\n",
      "    return (decontaminated * 255).astype(np.uint8)\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread(\"fixed_combined_foreground.png\")\n",
      "\n",
      "# Create a binary mask\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "_, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
      "\n",
      "# Apply color decontamination\n",
      "decontaminated = color_decontamination(img, mask)\n",
      "\n",
      "# Apply inpainting to fix artifacts\n",
      "inpainted = cv2.inpaint(decontaminated, 255 - mask, 3, cv2.INPAINT_TELEA)\n",
      "\n",
      "# Create a new mask from the inpainted result\n",
      "inpainted_gray = cv2.cvtColor(inpainted, cv2.COLOR_BGR2GRAY)\n",
      "_, new_mask = cv2.threshold(inpainted_gray, 1, 255, cv2.THRESH_BINARY)\n",
      "\n",
      "# Combine the original mask with the new mask\n",
      "combined_mask = cv2.bitwise_or(mask, new_mask)\n",
      "\n",
      "# Extract the foreground using the combined mask\n",
      "foreground_filled = cv2.bitwise_and(inpainted, inpainted, mask=combined_mask)\n",
      "\n",
      "# Display results\n",
      "cv2.imshow(\"Original\", img)\n",
      "cv2.imshow(\"Inpainted\", inpainted)\n",
      "cv2.imshow(\"Foreground Filled\", foreground_filled)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Save the result\n",
      "cv2.imwrite(\"foreground_filled_inpainted.png\", foreground_filled)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 19:\n",
      "%pip install tensorflow opencv-python numpy\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 20:\n",
      "import cv2\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "# Fungsi untuk memuat model U-Net\n",
      "def load_unet_model(model_path):\n",
      "    return tf.keras.models.load_model(model_path)\n",
      "\n",
      "# Fungsi untuk melakukan preprocessing pada gambar\n",
      "def preprocess_image(image):\n",
      "    image = cv2.resize(image, (256, 256))\n",
      "    image = image / 255.0\n",
      "    return image\n",
      "\n",
      "# Fungsi untuk melakukan postprocessing pada hasil prediksi\n",
      "def postprocess_prediction(prediction, original_shape):\n",
      "    prediction = (prediction > 0.5).astype(np.uint8) * 255\n",
      "    prediction = cv2.resize(prediction, (original_shape[1], original_shape[0]))\n",
      "    return prediction\n",
      "\n",
      "# Muat model U-Net (ganti dengan path ke model Anda)\n",
      "model = load_unet_model('path/to/unet_model.h5')\n",
      "\n",
      "# Baca gambar\n",
      "image = cv2.imread(\"fixed_combined_foreground.png\")\n",
      "original_shape = image.shape\n",
      "\n",
      "# Preprocess gambar\n",
      "preprocessed_image = preprocess_image(image)\n",
      "\n",
      "# Lakukan prediksi\n",
      "prediction = model.predict(np.expand_dims(preprocessed_image, axis=0))[0]\n",
      "\n",
      "# Postprocess hasil prediksi\n",
      "mask = postprocess_prediction(prediction[:,:,0], original_shape)\n",
      "\n",
      "# Aplikasikan mask ke gambar asli\n",
      "result = cv2.bitwise_and(image, image, mask=mask)\n",
      "\n",
      "# Tampilkan hasil\n",
      "cv2.imshow(\"Original Image\", image)\n",
      "cv2.imshow(\"U-Net Segmentation\", result)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Simpan hasil\n",
      "cv2.imwrite(\"unet_segmentation_result.png\", result)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 21:\n",
      "# Choose image\n",
      "def choose_image():\n",
      "    root = Tk()\n",
      "    root.withdraw()\n",
      "    file_path = filedialog.askopenfilename()\n",
      "    return file_path\n",
      "\n",
      "# Read fixed foreground and segmentation map\n",
      "fixed_foreground = cv2.imread(\"fixed_combined_foreground.png\")\n",
      "fixed_map = cv2.imread(\"fixed_segmentation_map.png\", cv2.IMREAD_GRAYSCALE)\n",
      "\n",
      "# Choose new background\n",
      "print(\"Choose an image for the new background:\")\n",
      "background_path = choose_image()\n",
      "new_background = cv2.imread(background_path)\n",
      "\n",
      "# Ensure the background size matches the foreground\n",
      "if new_background.shape[:2] != fixed_foreground.shape[:2]:\n",
      "    new_background = cv2.resize(new_background, (fixed_foreground.shape[1], fixed_foreground.shape[0]))\n",
      "\n",
      "# Create mask from segmentation map\n",
      "mask = fixed_map\n",
      "mask_inv = cv2.bitwise_not(mask)\n",
      "\n",
      "# Aplikasikan mask ke foreground dan background\n",
      "fg = cv2.bitwise_and(fixed_foreground, fixed_foreground, mask=mask)\n",
      "bg = cv2.bitwise_and(new_background, new_background, mask=mask_inv)\n",
      "\n",
      "# Gabungkan foreground dan background\n",
      "result = cv2.add(fg, bg)\n",
      "\n",
      "# Tampilkan hasil\n",
      "cv2.imshow(\"Original Foreground\", fixed_foreground)\n",
      "cv2.imshow(\"New Background\", new_background)\n",
      "cv2.imshow(\"Result\", result)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "\n",
      "# Simpan hasil\n",
      "cv2.imwrite(\"result_with_new_background.png\", result)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Code cell 22:\n",
      "import nbformat\n",
      "\n",
      "# Memuat file notebook\n",
      "file_path = r'C:\\BRIN\\BRIN\\Program\\Program 2\\Notebook\\Program2.1.ipynb'\n",
      "with open(file_path, 'r', encoding='utf-8') as f:\n",
      "    notebook_content = nbformat.read(f, as_version=4)\n",
      "\n",
      "# Mengekstrak sel-sel yang berisi kode\n",
      "code_cells = [cell['source'] for cell in notebook_content['cells'] if cell['cell_type'] == 'code']\n",
      "\n",
      "# Menampilkan semua kode yang ada dalam notebook\n",
      "for i, code in enumerate(code_cells):\n",
      "    print(f\"Code cell {i+1}:\\n{code}\\n{'-'*80}\\n\")\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "# Memuat file notebook\n",
    "file_path = r'C:\\BRIN\\BRIN\\Program\\Program 2\\Notebook\\Program2.1.ipynb'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Mengekstrak sel-sel yang berisi kode\n",
    "code_cells = [cell['source'] for cell in notebook_content['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "# Menampilkan semua kode yang ada dalam notebook\n",
    "for i, code in enumerate(code_cells):\n",
    "    print(f\"Code cell {i+1}:\\n{code}\\n{'-'*80}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
